#!/usr/bin/env python3
"""
Modu≈Ç do przygotowania kandydat√≥w na dane treningowe dla modelu spaCy NER
"""

import json
import pandas as pd
import re
import glob
from pathlib import Path
from typing import List, Dict, Set
from collections import defaultdict


class TrainingSetBuilder:
    """
    Klasa do budowania zestawu kandydat√≥w na dane treningowe
    """
    
    def __init__(self, csv_folder: str = "data/raw_reports/"):
        """
        Inicjalizacja
        
        Args:
            csv_folder: Folder z plikami CSV
        """
        self.csv_folder = Path(csv_folder)
        self.candidates = []
        self.unique_phrases = set()
        
        # Wzorce do wykrywania potencjalnych nazwisk
        self.name_patterns = [
            # Frazy z "ft.", "feat.", "z", "go≈õƒá", "rozmowa" (najwa≈ºniejsze)
            r'(?:ft\.|feat\.|z\s+|go≈õƒá[:\s]+|rozmowa\s+z\s+)([A-Z≈ÅƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º\s]{2,30})',
            
            # Frazy typu "ZAPRASZA MATEUSZ"
            r'\b(?:ZAPRASZA|GO≈öƒÜ|HOST|PROWADZI|ROZMAWIA)\s+([A-Z≈ÅƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]{2,20}(?:\s+[A-Z≈ÅƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]{2,20})?)\b',
            
            # 2-3 s≈Çowa z du≈ºej litery (Jan Kowalski, Anna Maria Nowak) - tylko je≈õli oba s≈Çowa sƒÖ nazwiskami
            r'\b[A-Z≈ÅƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]{2,15}\s+[A-Z≈ÅƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]{2,20}(?:\s+[A-Z≈ÅƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]{2,20})?\b',
            
            # Pseudonimy/arty≈õci (KIZO, BEDOES) - ale nie za kr√≥tkie
            r'\b[A-Z]{3,10}\b',
            
            # Mieszane wzorce (TroyBoi, KƒôKƒô, Ma≈Çpa) - ale tylko z charakterystycznymi wzorcami
            r'\b[A-Z≈ÅƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]{2,}[A-Z][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]{2,}\b'
        ]
        
        # S≈Çowa do filtrowania (nie sƒÖ nazwiskami)
        self.exclude_words = {
            'PODCAST', 'YOUTUBE', 'CHANNEL', 'VIDEO', 'MUSIC', 'SONG', 'ALBUM',
            'LIVE', 'STREAM', 'RADIO', 'TV', 'NEWS', 'SPORT', 'GAME', 'GAMING',
            'REVIEW', 'REACT', 'REACTION', 'TUTORIAL', 'GUIDE', 'TIPS', 'TRICKS',
            'BEST', 'TOP', 'WORST', 'FUNNY', 'EPIC', 'FAIL', 'WIN', 'COMPILATION',
            'OFFICIAL', 'FULL', 'COMPLETE', 'PART', 'EPISODE', 'SEASON', 'SERIES',
            'TRAILER', 'TEASER', 'BEHIND', 'SCENES', 'MAKING', 'DOCUMENTARY',
            'INTERVIEW', 'TALK', 'SHOW', 'PROGRAM', 'EMISJA', 'ODCINEK',
            'POLSKA', 'POLAND', 'POLISH', 'ENGLISH', 'GERMAN', 'FRENCH',
            'MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY',
            'STYCZE≈É', 'LUTY', 'MARZEC', 'KWIECIE≈É', 'MAJ', 'CZERWIEC',
            'LIPIEC', 'SIERPIE≈É', 'WRZESIE≈É', 'PA≈πDZIERNIK', 'LISTOPAD', 'GRUDZIE≈É',
            'JANUARY', 'FEBRUARY', 'MARCH', 'APRIL', 'JUNE', 'JULY',
            'AUGUST', 'SEPTEMBER', 'OCTOBER', 'NOVEMBER', 'DECEMBER',
            'ZDJƒòCIE', 'FOTOGRAFIA', 'PHOTO', 'PICTURE', 'IMAGE', 'ART', 'DESIGN',
            'SHORTS', 'LONG', 'LONGS', 'ELEKTRYCZNYCH', 'OWCACH', 'BOT√ìW', 'DW√ìCH',
            'PROF', 'DLACZEGO', 'HOSTEL', 'JEST', 'LEPSZY', 'HOTELU', 'B≈ÅAGA≈ÅEM',
            '≈ªEBYM', 'PRZETRWA≈Å', 'RANA', 'ROSJANIE', 'REAGUJƒÑ', 'POLAK√ìW',
            'NAPRAWDƒò', 'WYGLƒÑDA', '≈ªYCIE', 'KOREI', 'P√ì≈ÅNOCNEJ', 'POMYS≈ÅY',
            'BIZNES', 'POLSCE', 'PREMIUM', 'PREMIERY', 'WTOREK', 'GODZINIE'
        }
    
    def load_csv_files(self) -> List[pd.DataFrame]:
        """
        Wczytuje wszystkie pliki CSV z folderu
        
        Returns:
            Lista DataFrame z danymi
        """
        print(f"üìÅ Wczytywanie plik√≥w CSV z {self.csv_folder}")
        
        if not self.csv_folder.exists():
            print(f"‚ùå Folder {self.csv_folder} nie istnieje!")
            return []
        
        # Znajd≈∫ wszystkie pliki CSV
        csv_files = list(self.csv_folder.glob("*.csv"))
        
        if not csv_files:
            print(f"‚ö†Ô∏è  Nie znaleziono plik√≥w CSV w {self.csv_folder}")
            return []
        
        dataframes = []
        for csv_file in csv_files:
            try:
                df = pd.read_csv(csv_file)
                print(f"‚úÖ Wczytano: {csv_file.name} ({len(df)} rekord√≥w)")
                dataframes.append(df)
            except Exception as e:
                print(f"‚ùå B≈ÇƒÖd podczas wczytywania {csv_file.name}: {e}")
        
        return dataframes
    
    def clean_text(self, text: str) -> str:
        """
        Oczyszcza tekst przed analizƒÖ
        
        Args:
            text: Tekst do oczyszczenia
            
        Returns:
            Oczyszczony tekst
        """
        if pd.isna(text) or not text:
            return ""
        
        text = str(text)
        
        # Usu≈Ñ nadmiarowe bia≈Çe znaki
        text = re.sub(r'\s+', ' ', text.strip())
        
        # Usu≈Ñ znaki specjalne ale zostaw polskie znaki
        text = re.sub(r'[^\w\s\.\,\:\|\-\(\)\"\'ƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈ºƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª]', ' ', text)
        
        return text
    
    def is_valid_phrase(self, phrase: str) -> bool:
        """
        Sprawdza czy fraza jest potencjalnym nazwiskiem
        
        Args:
            phrase: Fraza do sprawdzenia
            
        Returns:
            True je≈õli fraza mo≈ºe byƒá nazwiskiem
        """
        phrase = phrase.strip()
        
        # Sprawd≈∫ d≈Çugo≈õƒá
        if len(phrase) < 2 or len(phrase) > 50:
            return False
        
        # Sprawd≈∫ czy nie zawiera cyfr
        if any(char.isdigit() for char in phrase):
            return False
        
        # Sprawd≈∫ czy nie jest w li≈õcie wyklucze≈Ñ
        phrase_upper = phrase.upper()
        for exclude_word in self.exclude_words:
            if exclude_word in phrase_upper:
                return False
        
        # Sprawd≈∫ czy zawiera przynajmniej jednƒÖ literƒô
        if not any(char.isalpha() for char in phrase):
            return False
        
        # Sprawd≈∫ czy nie ma za du≈ºo znak√≥w specjalnych
        special_chars = sum(1 for char in phrase if not char.isalnum() and char != ' ')
        if special_chars > len(phrase) * 0.3:
            return False
        
        return True
    
    def extract_candidates_from_text(self, text: str, source: str) -> List[Dict]:
        """
        WyciƒÖga kandydat√≥w z tekstu
        
        Args:
            text: Tekst do analizy
            source: ≈πr√≥d≈Ço tekstu (title, description, tags)
            
        Returns:
            Lista kandydat√≥w
        """
        candidates = []
        cleaned_text = self.clean_text(text)
        
        if not cleaned_text:
            return candidates
        
        # Zastosuj wszystkie wzorce
        for pattern in self.name_patterns:
            matches = re.findall(pattern, cleaned_text, re.IGNORECASE)
            
            for match in matches:
                # Je≈õli match to tuple (z grup), we≈∫ pierwszƒÖ grupƒô
                if isinstance(match, tuple):
                    phrase = match[0] if match[0] else match[1] if len(match) > 1 else ""
                else:
                    phrase = match
                
                phrase = phrase.strip()
                
                if self.is_valid_phrase(phrase) and phrase not in self.unique_phrases:
                    candidates.append({
                        "phrase": phrase,
                        "source": source
                    })
                    self.unique_phrases.add(phrase)
        
        return candidates
    
    def build_training_candidates(self, max_candidates: int = 200) -> List[Dict]:
        """
        Buduje listƒô kandydat√≥w na dane treningowe
        
        Args:
            max_candidates: Maksymalna liczba kandydat√≥w
            
        Returns:
            Lista kandydat√≥w
        """
        print(f"üîç WYSZUKIWANIE KANDYDAT√ìW NA DANE TRENINGOWE")
        print("=" * 60)
        
        # Wczytaj pliki CSV
        dataframes = self.load_csv_files()
        
        if not dataframes:
            return []
        
        # Po≈ÇƒÖcz wszystkie DataFrame
        all_data = pd.concat(dataframes, ignore_index=True)
        print(f"üìä ≈ÅƒÖcznie {len(all_data)} rekord√≥w do analizy")
        
        # Kolumny do analizy
        text_columns = ['Title', 'Description', 'Tags']
        
        # Sprawd≈∫ kt√≥re kolumny istniejƒÖ
        available_columns = []
        for col in text_columns:
            if col in all_data.columns:
                available_columns.append(col)
                print(f"‚úÖ Znaleziono kolumnƒô: {col}")
            else:
                print(f"‚ö†Ô∏è  Brak kolumny: {col}")
        
        if not available_columns:
            print("‚ùå Nie znaleziono ≈ºadnych kolumn tekstowych!")
            return []
        
        # WyciƒÖgnij kandydat√≥w z ka≈ºdej kolumny
        source_mapping = {
            'Title': 'title',
            'Description': 'description',
            'Tags': 'tags'
        }
        
        for column in available_columns:
            source = source_mapping.get(column, column.lower())
            print(f"\nüîç Analizujƒô kolumnƒô: {column}")
            
            processed = 0
            for _, row in all_data.iterrows():
                text = row.get(column, '')
                new_candidates = self.extract_candidates_from_text(text, source)
                self.candidates.extend(new_candidates)
                processed += 1
                
                if processed % 100 == 0:
                    print(f"   Przetworzono {processed} rekord√≥w...")
                
                # Limit kandydat√≥w
                if len(self.candidates) >= max_candidates:
                    break
            
            print(f"   Znaleziono {len([c for c in self.candidates if c['source'] == source])} kandydat√≥w")
            
            if len(self.candidates) >= max_candidates:
                break
        
        # Ogranicz do max_candidates
        if len(self.candidates) > max_candidates:
            self.candidates = self.candidates[:max_candidates]
        
        print(f"\n‚úÖ ≈ÅƒÖcznie znaleziono {len(self.candidates)} unikalnych kandydat√≥w")
        
        return self.candidates
    
    def save_candidates(self, output_file: str = "data/feedback_candidates.json"):
        """
        Zapisuje kandydat√≥w do pliku JSON
        
        Args:
            output_file: ≈öcie≈ºka do pliku wynikowego
        """
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.candidates, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ Zapisano kandydat√≥w: {output_file}")
            
            # Statystyki
            source_stats = defaultdict(int)
            for candidate in self.candidates:
                source_stats[candidate['source']] += 1
            
            print(f"\nüìä Statystyki ≈∫r√≥de≈Ç:")
            for source, count in source_stats.items():
                print(f"   {source}: {count}")
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas zapisywania: {e}")


def main():
    """
    G≈Ç√≥wna funkcja do budowania kandydat√≥w
    """
    builder = TrainingSetBuilder()
    candidates = builder.build_training_candidates(max_candidates=200)
    
    if candidates:
        builder.save_candidates()
        
        print(f"\nüéØ PRZYK≈ÅADOWE KANDYDACI:")
        print("-" * 40)
        for i, candidate in enumerate(candidates[:10], 1):
            print(f"{i:2d}. \"{candidate['phrase']}\" ({candidate['source']})")
        
        if len(candidates) > 10:
            print(f"    ... i {len(candidates) - 10} wiƒôcej")
    
    print(f"\nüéâ BUDOWANIE KANDYDAT√ìW ZAKO≈ÉCZONE!")


if __name__ == "__main__":
    main()