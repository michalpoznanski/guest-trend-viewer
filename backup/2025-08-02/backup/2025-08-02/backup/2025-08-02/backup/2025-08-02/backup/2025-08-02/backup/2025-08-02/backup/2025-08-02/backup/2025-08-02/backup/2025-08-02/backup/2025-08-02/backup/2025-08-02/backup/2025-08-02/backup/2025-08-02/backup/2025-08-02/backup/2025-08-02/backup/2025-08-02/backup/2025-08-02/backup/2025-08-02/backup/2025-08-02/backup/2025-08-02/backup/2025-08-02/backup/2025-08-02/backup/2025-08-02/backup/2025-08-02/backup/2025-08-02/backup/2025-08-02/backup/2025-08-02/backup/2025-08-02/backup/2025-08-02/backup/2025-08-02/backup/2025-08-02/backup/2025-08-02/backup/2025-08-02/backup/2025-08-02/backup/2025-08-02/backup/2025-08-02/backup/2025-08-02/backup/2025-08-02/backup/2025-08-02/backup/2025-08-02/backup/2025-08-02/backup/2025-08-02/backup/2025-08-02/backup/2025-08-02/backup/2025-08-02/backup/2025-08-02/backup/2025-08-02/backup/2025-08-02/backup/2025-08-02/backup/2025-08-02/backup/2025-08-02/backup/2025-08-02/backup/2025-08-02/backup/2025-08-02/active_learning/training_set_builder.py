#!/usr/bin/env python3
"""
ModuÅ‚ do przygotowania kandydatÃ³w na dane treningowe dla modelu spaCy NER
"""

import json
import pandas as pd
import re
import glob
from pathlib import Path
from typing import List, Dict, Set
from collections import defaultdict


class TrainingSetBuilder:
    """
    Klasa do budowania zestawu kandydatÃ³w na dane treningowe
    """
    
    def __init__(self, csv_folder: str = "data/raw_reports/"):
        """
        Inicjalizacja
        
        Args:
            csv_folder: Folder z plikami CSV
        """
        self.csv_folder = Path(csv_folder)
        self.candidates = []
        self.unique_phrases = set()
        
        # Wzorce do wykrywania potencjalnych nazwisk
        self.name_patterns = [
            # Frazy z "ft.", "feat.", "z", "goÅ›Ä‡", "rozmowa" (najwaÅ¼niejsze)
            r'(?:ft\.|feat\.|z\s+|goÅ›Ä‡[:\s]+|rozmowa\s+z\s+)([A-ZÅÄ„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»][a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼\s]{2,30})',
            
            # Frazy typu "ZAPRASZA MATEUSZ"
            r'\b(?:ZAPRASZA|GOÅšÄ†|HOST|PROWADZI|ROZMAWIA)\s+([A-ZÅÄ„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»][a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]{2,20}(?:\s+[A-ZÅÄ„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»][a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]{2,20})?)\b',
            
            # 2-3 sÅ‚owa z duÅ¼ej litery (Jan Kowalski, Anna Maria Nowak) - tylko jeÅ›li oba sÅ‚owa sÄ… nazwiskami
            r'\b[A-ZÅÄ„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»][a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]{2,15}\s+[A-ZÅÄ„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»][a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]{2,20}(?:\s+[A-ZÅÄ„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»][a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]{2,20})?\b',
            
            # Pseudonimy/artyÅ›ci (KIZO, BEDOES) - ale nie za krÃ³tkie
            r'\b[A-Z]{3,10}\b',
            
            # Mieszane wzorce (TroyBoi, KÄ™KÄ™, MaÅ‚pa) - ale tylko z charakterystycznymi wzorcami
            r'\b[A-ZÅÄ„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»][a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]{2,}[A-Z][a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]{2,}\b'
        ]
        
        # SÅ‚owa do filtrowania (nie sÄ… nazwiskami)
        self.exclude_words = {
            'PODCAST', 'YOUTUBE', 'CHANNEL', 'VIDEO', 'MUSIC', 'SONG', 'ALBUM',
            'LIVE', 'STREAM', 'RADIO', 'TV', 'NEWS', 'SPORT', 'GAME', 'GAMING',
            'REVIEW', 'REACT', 'REACTION', 'TUTORIAL', 'GUIDE', 'TIPS', 'TRICKS',
            'BEST', 'TOP', 'WORST', 'FUNNY', 'EPIC', 'FAIL', 'WIN', 'COMPILATION',
            'OFFICIAL', 'FULL', 'COMPLETE', 'PART', 'EPISODE', 'SEASON', 'SERIES',
            'TRAILER', 'TEASER', 'BEHIND', 'SCENES', 'MAKING', 'DOCUMENTARY',
            'INTERVIEW', 'TALK', 'SHOW', 'PROGRAM', 'EMISJA', 'ODCINEK',
            'POLSKA', 'POLAND', 'POLISH', 'ENGLISH', 'GERMAN', 'FRENCH',
            'MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY',
            'STYCZEÅƒ', 'LUTY', 'MARZEC', 'KWIECIEÅƒ', 'MAJ', 'CZERWIEC',
            'LIPIEC', 'SIERPIEÅƒ', 'WRZESIEÅƒ', 'PAÅ¹DZIERNIK', 'LISTOPAD', 'GRUDZIEÅƒ',
            'JANUARY', 'FEBRUARY', 'MARCH', 'APRIL', 'JUNE', 'JULY',
            'AUGUST', 'SEPTEMBER', 'OCTOBER', 'NOVEMBER', 'DECEMBER',
            'ZDJÄ˜CIE', 'FOTOGRAFIA', 'PHOTO', 'PICTURE', 'IMAGE', 'ART', 'DESIGN',
            'SHORTS', 'LONG', 'LONGS', 'ELEKTRYCZNYCH', 'OWCACH', 'BOTÃ“W', 'DWÃ“CH',
            'PROF', 'DLACZEGO', 'HOSTEL', 'JEST', 'LEPSZY', 'HOTELU', 'BÅAGAÅEM',
            'Å»EBYM', 'PRZETRWAÅ', 'RANA', 'ROSJANIE', 'REAGUJÄ„', 'POLAKÃ“W',
            'NAPRAWDÄ˜', 'WYGLÄ„DA', 'Å»YCIE', 'KOREI', 'PÃ“ÅNOCNEJ', 'POMYSÅY',
            'BIZNES', 'POLSCE', 'PREMIUM', 'PREMIERY', 'WTOREK', 'GODZINIE'
        }
    
    def load_csv_files(self) -> List[pd.DataFrame]:
        """
        Wczytuje wszystkie pliki CSV z folderu
        
        Returns:
            Lista DataFrame z danymi
        """
        print(f"ğŸ“ Wczytywanie plikÃ³w CSV z {self.csv_folder}")
        
        if not self.csv_folder.exists():
            print(f"âŒ Folder {self.csv_folder} nie istnieje!")
            return []
        
        # ZnajdÅº wszystkie pliki CSV
        csv_files = list(self.csv_folder.glob("*.csv"))
        
        if not csv_files:
            print(f"âš ï¸  Nie znaleziono plikÃ³w CSV w {self.csv_folder}")
            return []
        
        dataframes = []
        for csv_file in csv_files:
            try:
                df = pd.read_csv(csv_file)
                print(f"âœ… Wczytano: {csv_file.name} ({len(df)} rekordÃ³w)")
                dataframes.append(df)
            except Exception as e:
                print(f"âŒ BÅ‚Ä…d podczas wczytywania {csv_file.name}: {e}")
        
        return dataframes
    
    def clean_text(self, text: str) -> str:
        """
        Oczyszcza tekst przed analizÄ…
        
        Args:
            text: Tekst do oczyszczenia
            
        Returns:
            Oczyszczony tekst
        """
        if pd.isna(text) or not text:
            return ""
        
        text = str(text)
        
        # UsuÅ„ nadmiarowe biaÅ‚e znaki
        text = re.sub(r'\s+', ' ', text.strip())
        
        # UsuÅ„ znaki specjalne ale zostaw polskie znaki
        text = re.sub(r'[^\w\s\.\,\:\|\-\(\)\"\'Ä…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼Ä„Ä†Ä˜ÅÅƒÃ“ÅšÅ¹Å»]', ' ', text)
        
        return text
    
    def is_valid_phrase(self, phrase: str) -> bool:
        """
        Sprawdza czy fraza jest potencjalnym nazwiskiem
        
        Args:
            phrase: Fraza do sprawdzenia
            
        Returns:
            True jeÅ›li fraza moÅ¼e byÄ‡ nazwiskiem
        """
        phrase = phrase.strip()
        
        # SprawdÅº dÅ‚ugoÅ›Ä‡
        if len(phrase) < 2 or len(phrase) > 50:
            return False
        
        # SprawdÅº czy nie zawiera cyfr
        if any(char.isdigit() for char in phrase):
            return False
        
        # SprawdÅº czy nie jest w liÅ›cie wykluczeÅ„
        phrase_upper = phrase.upper()
        for exclude_word in self.exclude_words:
            if exclude_word in phrase_upper:
                return False
        
        # SprawdÅº czy zawiera przynajmniej jednÄ… literÄ™
        if not any(char.isalpha() for char in phrase):
            return False
        
        # SprawdÅº czy nie ma za duÅ¼o znakÃ³w specjalnych
        special_chars = sum(1 for char in phrase if not char.isalnum() and char != ' ')
        if special_chars > len(phrase) * 0.3:
            return False
        
        return True
    
    def extract_candidates_from_text(self, text: str, source: str) -> List[Dict]:
        """
        WyciÄ…ga kandydatÃ³w z tekstu
        
        Args:
            text: Tekst do analizy
            source: Å¹rÃ³dÅ‚o tekstu (title, description, tags)
            
        Returns:
            Lista kandydatÃ³w
        """
        candidates = []
        cleaned_text = self.clean_text(text)
        
        if not cleaned_text:
            return candidates
        
        # Zastosuj wszystkie wzorce
        for pattern in self.name_patterns:
            matches = re.findall(pattern, cleaned_text, re.IGNORECASE)
            
            for match in matches:
                # JeÅ›li match to tuple (z grup), weÅº pierwszÄ… grupÄ™
                if isinstance(match, tuple):
                    phrase = match[0] if match[0] else match[1] if len(match) > 1 else ""
                else:
                    phrase = match
                
                phrase = phrase.strip()
                
                if self.is_valid_phrase(phrase) and phrase not in self.unique_phrases:
                    candidates.append({
                        "phrase": phrase,
                        "source": source
                    })
                    self.unique_phrases.add(phrase)
        
        return candidates
    
    def build_training_candidates(self, max_candidates: int = 200) -> List[Dict]:
        """
        Buduje listÄ™ kandydatÃ³w na dane treningowe
        
        Args:
            max_candidates: Maksymalna liczba kandydatÃ³w
            
        Returns:
            Lista kandydatÃ³w
        """
        print(f"ğŸ” WYSZUKIWANIE KANDYDATÃ“W NA DANE TRENINGOWE")
        print("=" * 60)
        
        # Wczytaj pliki CSV
        dataframes = self.load_csv_files()
        
        if not dataframes:
            return []
        
        # PoÅ‚Ä…cz wszystkie DataFrame
        all_data = pd.concat(dataframes, ignore_index=True)
        print(f"ğŸ“Š ÅÄ…cznie {len(all_data)} rekordÃ³w do analizy")
        
        # Kolumny do analizy
        text_columns = ['Title', 'Description', 'Tags']
        
        # SprawdÅº ktÃ³re kolumny istniejÄ…
        available_columns = []
        for col in text_columns:
            if col in all_data.columns:
                available_columns.append(col)
                print(f"âœ… Znaleziono kolumnÄ™: {col}")
            else:
                print(f"âš ï¸  Brak kolumny: {col}")
        
        if not available_columns:
            print("âŒ Nie znaleziono Å¼adnych kolumn tekstowych!")
            return []
        
        # WyciÄ…gnij kandydatÃ³w z kaÅ¼dej kolumny
        source_mapping = {
            'Title': 'title',
            'Description': 'description',
            'Tags': 'tags'
        }
        
        for column in available_columns:
            source = source_mapping.get(column, column.lower())
            print(f"\nğŸ” AnalizujÄ™ kolumnÄ™: {column}")
            
            processed = 0
            for _, row in all_data.iterrows():
                text = row.get(column, '')
                new_candidates = self.extract_candidates_from_text(text, source)
                self.candidates.extend(new_candidates)
                processed += 1
                
                if processed % 100 == 0:
                    print(f"   Przetworzono {processed} rekordÃ³w...")
                
                # Limit kandydatÃ³w
                if len(self.candidates) >= max_candidates:
                    break
            
            print(f"   Znaleziono {len([c for c in self.candidates if c['source'] == source])} kandydatÃ³w")
            
            if len(self.candidates) >= max_candidates:
                break
        
        # Ogranicz do max_candidates
        if len(self.candidates) > max_candidates:
            self.candidates = self.candidates[:max_candidates]
        
        print(f"\nâœ… ÅÄ…cznie znaleziono {len(self.candidates)} unikalnych kandydatÃ³w")
        
        return self.candidates
    
    def save_candidates(self, output_file: str = "data/feedback_candidates.json"):
        """
        Zapisuje kandydatÃ³w do pliku JSON
        
        Args:
            output_file: ÅšcieÅ¼ka do pliku wynikowego
        """
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.candidates, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… Zapisano kandydatÃ³w: {output_file}")
            
            # Statystyki
            source_stats = defaultdict(int)
            for candidate in self.candidates:
                source_stats[candidate['source']] += 1
            
            print(f"\nğŸ“Š Statystyki ÅºrÃ³deÅ‚:")
            for source, count in source_stats.items():
                print(f"   {source}: {count}")
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d podczas zapisywania: {e}")


def main():
    """
    GÅ‚Ã³wna funkcja do budowania kandydatÃ³w
    """
    builder = TrainingSetBuilder()
    candidates = builder.build_training_candidates(max_candidates=200)
    
    if candidates:
        builder.save_candidates()
        
        print(f"\nğŸ¯ PRZYKÅADOWE KANDYDACI:")
        print("-" * 40)
        for i, candidate in enumerate(candidates[:10], 1):
            print(f"{i:2d}. \"{candidate['phrase']}\" ({candidate['source']})")
        
        if len(candidates) > 10:
            print(f"    ... i {len(candidates) - 10} wiÄ™cej")
    
    print(f"\nğŸ‰ BUDOWANIE KANDYDATÃ“W ZAKOÅƒCZONE!")


if __name__ == "__main__":
    main()