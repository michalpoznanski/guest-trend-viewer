import json
import random
from pathlib import Path
from typing import List, Dict, Any
import spacy
from spacy.tokens import DocBin


def load_training_data(jsonl_path: str) -> List[Dict[str, Any]]:
    """
    Wczytuje dane treningowe z pliku JSON Lines
    """
    data = []
    with open(jsonl_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                data.append(json.loads(line))
    return data


def convert_to_spacy_format(data: List[Dict[str, Any]], nlp) -> List[Dict[str, Any]]:
    """
    Konwertuje dane do formatu spaCy
    """
    spacy_data = []
    
    for item in data:
        text = item['text']
        entities = item['entities']
        
        # UtwÃ³rz dokument spaCy
        doc = nlp.make_doc(text)
        
        # Dodaj encje
        ents = []
        for start, end, label in entities:
            # SprawdÅº czy pozycje sÄ… poprawne
            if start < len(text) and end <= len(text) and start < end:
                span = doc.char_span(start, end, label=label)
                if span is not None:
                    ents.append(span)
        
        doc.ents = ents
        spacy_data.append(doc)
    
    return spacy_data


def split_data(data: List, train_ratio: float = 0.8, random_seed: int = 42) -> tuple:
    """
    Dzieli dane na zbiÃ³r treningowy i walidacyjny
    """
    random.seed(random_seed)
    random.shuffle(data)
    
    split_idx = int(len(data) * train_ratio)
    train_data = data[:split_idx]
    dev_data = data[split_idx:]
    
    return train_data, dev_data


def save_spacy_data(data: List, output_path: str):
    """
    Zapisuje dane w formacie binarnym spaCy
    """
    doc_bin = DocBin()
    for doc in data:
        doc_bin.add(doc)
    
    with open(output_path, 'wb') as f:
        f.write(doc_bin.to_bytes())


def main():
    """
    GÅ‚Ã³wna funkcja konwersji danych
    """
    print("ğŸ”„ KONWERSJA DANYCH TRENINGOWYCH DO FORMATU SPACY")
    print("=" * 50)
    
    # ÅšcieÅ¼ki
    input_file = Path("data/training_data.jsonl")
    train_output = Path("training/train.spacy")
    dev_output = Path("training/dev.spacy")
    
    # SprawdÅº czy plik wejÅ›ciowy istnieje
    if not input_file.exists():
        print(f"âŒ Plik {input_file} nie istnieje!")
        print("Najpierw uruchom: python analyzer/prepare_training_data.py")
        return
    
    # Wczytaj dane
    print(f"ğŸ“– Wczytywanie danych z {input_file}...")
    data = load_training_data(input_file)
    print(f"âœ… Wczytano {len(data)} rekordÃ³w")
    
    if len(data) == 0:
        print("âŒ Brak danych do konwersji!")
        return
    
    # Inicjalizuj spaCy (pusty model)
    print("ğŸ”§ Inicjalizacja spaCy...")
    nlp = spacy.blank("pl")
    
    # Konwertuj do formatu spaCy
    print("ğŸ”„ Konwersja do formatu spaCy...")
    spacy_data = convert_to_spacy_format(data, nlp)
    print(f"âœ… Skonwertowano {len(spacy_data)} dokumentÃ³w")
    
    # Podziel dane
    print("ğŸ“Š Dzielenie danych (80% train / 20% dev)...")
    train_data, dev_data = split_data(spacy_data)
    print(f"âœ… Train: {len(train_data)} dokumentÃ³w")
    print(f"âœ… Dev: {len(dev_data)} dokumentÃ³w")
    
    # Zapisz pliki
    print("ğŸ’¾ ZapisujÄ™ pliki...")
    save_spacy_data(train_data, train_output)
    save_spacy_data(dev_data, dev_output)
    
    print(f"âœ… Zapisano: {train_output}")
    print(f"âœ… Zapisano: {dev_output}")
    
    # Statystyki
    total_entities = sum(len(doc.ents) for doc in spacy_data)
    print(f"\nğŸ“ˆ Statystyki:")
    print(f"   ÅÄ…czna liczba encji: {total_entities}")
    
    if total_entities > 0:
        label_counts = {}
        for doc in spacy_data:
            for ent in doc.ents:
                label_counts[ent.label_] = label_counts.get(ent.label_, 0) + 1
        
        print("   RozkÅ‚ad etykiet:")
        for label, count in label_counts.items():
            print(f"     {label}: {count}")
    
    print(f"\nğŸ‰ KONWERSJA ZAKOÅƒCZONA!")
    print(f"MoÅ¼esz teraz uruchomiÄ‡ trening: bash training/train.sh")


if __name__ == "__main__":
    main() 